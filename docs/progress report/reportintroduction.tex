\chapter{Introdução}

\section{Contextualização}
Nos últimos anos, o processamento de grandes quantidades de dados tem sido um tópico de grande interesse. Contudo, a análise das estruturas envolvidas no processo 
é normalmente complexa. De modo a diminuir a complexidade envolvida no tratamento deste tipo de estruturas surgiram algumas plataformas seguindo o modelo \textit{Map Reduce}, como o Apache Hadoop~\cite{hadoop}.

O Apache Hadoop~\cite{hadoop} é uma plataforma que visa facilitar o processamento e análise de estruturas de dimensões consideráveis em ambientes distribuídos, a qual tem sido muito utilizada.

A plataforma oferece um conjunto de benefícios tais como a sua interface simples de programação, escalabilidade e de ser tolerante a falhas.
Esta plataforma é composta por quatro módulos:
Hadoop Common (conjunto de ferramentas que servem de suporte a outros módulos),
Hadoop Distributed File System (sistema de ficheiros distribuído),
Hadoop Yarn (plataforma que disponibiliza o agendamento de tarefas)
e o Hadoop Map Reduce (módulo que usa o modelo de programação Map Reduce para o processamento de dados e agenda tarefas usando o Hadoop Yarn)

Apesar dos benefícios de se usar este tipo de plataforma para alguns tipos de dados, e ser possível a sua utilização para o processamento de redes através múltiplas invocações de Map Reduce, o modelo de programação usado  não é o mais adequado para o processamento de grafos devido à existência de  uma elevada complexidade envolvida na implementação de algoritmos e um custo computacional indesejado.
Para resolver este problema foi proposto pela Google uma plataforma, denominada Pregel\cite{pregel}, que se baseia no modelo de programação Bulk Synchronous Parallel\cite{bsp}.

Baseando-se na implementação da Google foram surgindo implementações \textit{open-source} como o GPS\cite{docgps}, Apache Hama\cite{hama} e Apache Giraph\cite{giraph}.


\section{Descrição do projecto}
Apesar de existirem alguns algoritmos implementados nos ambientes descritos anteriormente, o objetivo deste projeto é analisar as plataformas
baseadas no modelo \textit{Bulk Synchronous Parallel}, de modo a criar uma biblioteca modular que contenha um conjunto de algoritmos que possam ser utilizados para \textit{clustering} e que não dependa de uma única plataforma. As principais plataformas que serão estudadas para o desenvolvimento desta biblioteca será o Apache Hama e o Apache Giraph. 
O Apache Giraph é uma plataforma de interesse tendo em conta que usa como base o Apache Hadoop para o agendamento de tarefas, o que simplifica o seu uso
para todas as infraestruturas que usam Apache Hadoop. O Apache Hama, como proporciona um modelo mais perto do \textit{Bulk Synchronous Parallel} do que o Apache Giraph, é também ser alvo de estudo para esta biblioteca.


\section{Recursos}
Este projeto será desenvolvido com recurso a ferramentas e plataformas \textit{open source}.
As plataforma e ferramentas serão:
\begin{itemize}
 \item Java SDK 7
 \item Apache Hadoop 1.2.1
 \item Apache Giraph 1.1.0
 \item Apache Hama 0.6.4
\end{itemize}

O equipamento físico para obtenção de resultados sobre os algoritmos desenvolvidos será disponibilizado pelo INESC-ID. 
O equipamento inclui 8 máquinas virtuais com 1 CPU a 2.3GHz e 3GB de RAM tendo cada imagem 8Gb( havendo acesso a um disco extra de 32Gb) e o seu sistema operativo é Slackware 14.1 64bits.
As máquinas virtuais estão hospedadas em dois servidores dedicados cada um deles com 16Gb de RAM e 4 CPUs, em ambiente Linux através de KVM.

\section{Calendarização}
O projeto está a ser realizado segundo o seguinte planeamento presente na tabela~\ref{table:planeamento}
\begin{table}
 \caption{ Calendarização semanal}
\label{table:planeamento}
 \begin{tabular}{|l|l|p{9.5cm}|}
 \hline
 \bf{Data de Inicio} & \bf{Semana} & \bf{Descrição} \\ \hline
 3 Março & 1 & Escrita da Proposta \\ \hline
 10 Março & 2 & Finalização da Proposta e iniciação do estudo das Plataformas \\ \hline
 17 Março & 3 & Estudo das Plataformas e levantamento das interfaces programáveis. \\ \hline
 22 Março & 4 & Estudo dos algoritmos \textit{k-core}, \textit{heat kernel} e \textit{BFS}  \\ \hline
 31 Março & 5-6 & Estudo dos algoritmos \textit {Layered Label Propagation} e \textit{Louvain}. Estruturar e implementar os vários módulos da biblioteca.\\ \hline
 14 Abril & 7 & Continuação da estruturação e implementação dos módulos da biblioteca.\\ \hline
 21 Abril & 8 & Implementação dos algoritmos estudados na 4ª semana. Relatório de progresso.\\ \hline
 28 Abril & 9 & Preparação da apresentação individual e relatório de progresso. \\ \hline
 5 Maio & 10 & Continuação da implementação dos algoritmos estudados na 4ª semana. Início da implementação dos algoritmos \textit{Louvain} e \textit{Layered Label Propagation}. \\\hline
 12 Maio & 11-12 & Continuação da implementação dos algoritmos \textit{Louvain} e \textit{Layered Label Propagation}.\\ \hline
 26 Maio & 13-14 & Estudar e implementar o algoritmo de \textit{Betweenness Centrality}. \\ \hline
 9 Junho & 15 & Cartaz e finalização da versão com a implementação dos algoritmos obrigatórios. \\ \hline
 16 Junho & 16 & Configuração das máquinas virtuais. Preparação da biblioteca e dos algoritmos para correr em ambientes distribuídos.\\ \hline
 23 Junho & 17-19 &  Escolha dos \textit{data-sets} (que iram ser usados nos testes), testes e comparações com outras plataformas. \\ \hline
 14 Julho & 20 & Finalização do relatório e entrega da versão final. \\ \hline
\end{tabular}
\end{table}

A semana 16 será agora usada para configurar as máquinas onde os algoritmos serão executados e criar executáveis configuráveis que possam facilmente ser usados em ambientes distribuídos.